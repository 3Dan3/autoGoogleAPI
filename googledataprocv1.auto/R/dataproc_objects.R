#' Google Cloud Dataproc API Objects 
#' Manages Hadoop-based clusters and jobs on Google Cloud Platform.
#' 
#' Auto-generated code by googleAuthR::gar_create_api_objects
#'  at 2016-09-03 23:18:50
#' filename: /Users/mark/dev/R/autoGoogleAPI/googledataprocv1.auto/R/dataproc_objects.R
#' api_json: api_json
#' 
#' Objects for use by the functions created by googleAuthR::gar_create_api_skeleton

#' Cluster Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Describes the identifying information, config, and status of a cluster of Google Compute Engine instances.
#' 
#' @param projectId [Required] The Google Cloud Platform project ID that the cluster belongs to
#' @param clusterName [Required] The cluster name
#' @param config [Required] The cluster config
#' @param status [Output-only] Cluster status
#' @param statusHistory [Output-only] The previous cluster status
#' @param clusterUuid [Output-only] A cluster UUID (Unique Universal Identifier)
#' 
#' @return Cluster object
#' 
#' @family Cluster functions
#' @export
Cluster <- function(projectId = NULL, clusterName = NULL, config = NULL, status = NULL, 
    statusHistory = NULL, clusterUuid = NULL) {
    structure(list(projectId = projectId, clusterName = clusterName, config = config, 
        status = status, statusHistory = statusHistory, clusterUuid = clusterUuid), 
        class = "gar_Cluster")
}

#' ClusterConfig Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' The cluster config.
#' 
#' @param configBucket [Optional] A Google Cloud Storage staging bucket used for sharing generated SSH keys and config
#' @param gceClusterConfig [Required] The shared Google Compute Engine config settings for all instances in a cluster
#' @param masterConfig [Optional] The Google Compute Engine config settings for the master instance in a cluster
#' @param workerConfig [Optional] The Google Compute Engine config settings for worker instances in a cluster
#' @param secondaryWorkerConfig [Optional] The Google Compute Engine config settings for additional worker instances in a cluster
#' @param softwareConfig [Optional] The config settings for software inside the cluster
#' @param initializationActions [Optional] Commands to execute on each node after config is completed
#' 
#' @return ClusterConfig object
#' 
#' @family ClusterConfig functions
#' @export
ClusterConfig <- function(configBucket = NULL, gceClusterConfig = NULL, masterConfig = NULL, 
    workerConfig = NULL, secondaryWorkerConfig = NULL, softwareConfig = NULL, initializationActions = NULL) {
    structure(list(configBucket = configBucket, gceClusterConfig = gceClusterConfig, 
        masterConfig = masterConfig, workerConfig = workerConfig, secondaryWorkerConfig = secondaryWorkerConfig, 
        softwareConfig = softwareConfig, initializationActions = initializationActions), 
        class = "gar_ClusterConfig")
}

#' GceClusterConfig Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Common config settings for resources of Google Compute Engine cluster instances, applicable to all instances in the cluster.
#' 
#' @param GceClusterConfig.metadata The \link{GceClusterConfig.metadata} object or list of objects
#' @param zoneUri [Required] The zone where the Google Compute Engine cluster will be located
#' @param networkUri The Google Compute Engine network to be used for machine communications
#' @param subnetworkUri The Google Compute Engine subnetwork to be used for machine communications
#' @param serviceAccountScopes The URIs of service account scopes to be included in Google Compute Engine instances
#' @param tags The Google Compute Engine tags to add to all instances
#' @param metadata The Google Compute Engine metadata entries to add to all instances
#' 
#' @return GceClusterConfig object
#' 
#' @family GceClusterConfig functions
#' @export
GceClusterConfig <- function(GceClusterConfig.metadata = NULL, zoneUri = NULL, networkUri = NULL, 
    subnetworkUri = NULL, serviceAccountScopes = NULL, tags = NULL, metadata = NULL) {
    structure(list(GceClusterConfig.metadata = GceClusterConfig.metadata, zoneUri = zoneUri, 
        networkUri = networkUri, subnetworkUri = subnetworkUri, serviceAccountScopes = serviceAccountScopes, 
        tags = tags, metadata = metadata), class = "gar_GceClusterConfig")
}

#' GceClusterConfig.metadata Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' The Google Compute Engine metadata entries to add to all instances.
#' 
#' 
#' 
#' @return GceClusterConfig.metadata object
#' 
#' @family GceClusterConfig functions
#' @export
GceClusterConfig.metadata <- function() {
    list()
}

#' InstanceGroupConfig Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' The config settings for Google Compute Engine resources in an instance group, such as a master or worker group.
#' 
#' @param numInstances The number of VM instances in the instance group
#' @param instanceNames The list of instance names
#' @param imageUri [Output-only] The Google Compute Engine image resource used for cluster instances
#' @param machineTypeUri The Google Compute Engine machine type used for cluster instances
#' @param diskConfig Disk option config settings
#' @param isPreemptible Specifies that this instance group contains Preemptible Instances
#' @param managedGroupConfig [Output-only] The config for Google Compute Engine Instance Group Manager that manages this group
#' 
#' @return InstanceGroupConfig object
#' 
#' @family InstanceGroupConfig functions
#' @export
InstanceGroupConfig <- function(numInstances = NULL, instanceNames = NULL, imageUri = NULL, 
    machineTypeUri = NULL, diskConfig = NULL, isPreemptible = NULL, managedGroupConfig = NULL) {
    structure(list(numInstances = numInstances, instanceNames = instanceNames, imageUri = imageUri, 
        machineTypeUri = machineTypeUri, diskConfig = diskConfig, isPreemptible = isPreemptible, 
        managedGroupConfig = managedGroupConfig), class = "gar_InstanceGroupConfig")
}

#' DiskConfig Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Specifies the config of disk options for a group of VM instances.
#' 
#' @param bootDiskSizeGb [Optional] Size in GB of the boot disk (default is 500GB)
#' @param numLocalSsds [Optional] Number of attached SSDs, from 0 to 4 (default is 0)
#' 
#' @return DiskConfig object
#' 
#' @family DiskConfig functions
#' @export
DiskConfig <- function(bootDiskSizeGb = NULL, numLocalSsds = NULL) {
    structure(list(bootDiskSizeGb = bootDiskSizeGb, numLocalSsds = numLocalSsds), 
        class = "gar_DiskConfig")
}

#' ManagedGroupConfig Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Specifies the resources used to actively manage an instance group.
#' 
#' @param instanceTemplateName [Output-only] The name of the Instance Template used for the Managed Instance Group
#' @param instanceGroupManagerName [Output-only] The name of the Instance Group Manager for this group
#' 
#' @return ManagedGroupConfig object
#' 
#' @family ManagedGroupConfig functions
#' @export
ManagedGroupConfig <- function(instanceTemplateName = NULL, instanceGroupManagerName = NULL) {
    structure(list(instanceTemplateName = instanceTemplateName, instanceGroupManagerName = instanceGroupManagerName), 
        class = "gar_ManagedGroupConfig")
}

#' SoftwareConfig Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Specifies the selection and config of software inside the cluster.
#' 
#' @param SoftwareConfig.properties The \link{SoftwareConfig.properties} object or list of objects
#' @param imageVersion [Optional] The version of software inside the cluster
#' @param properties [Optional] The properties to set on daemon config files
#' 
#' @return SoftwareConfig object
#' 
#' @family SoftwareConfig functions
#' @export
SoftwareConfig <- function(SoftwareConfig.properties = NULL, imageVersion = NULL, 
    properties = NULL) {
    structure(list(SoftwareConfig.properties = SoftwareConfig.properties, imageVersion = imageVersion, 
        properties = properties), class = "gar_SoftwareConfig")
}

#' SoftwareConfig.properties Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' [Optional] The properties to set on daemon config files. Property keys are specified in `prefix:property` format, such as `core:fs.defaultFS`. The following are supported prefixes and their mappings: * core: `core-site.xml` * hdfs: `hdfs-site.xml` * mapred: `mapred-site.xml` * yarn: `yarn-site.xml` * hive: `hive-site.xml` * pig: `pig.properties` * spark: `spark-defaults.conf`
#' 
#' 
#' 
#' @return SoftwareConfig.properties object
#' 
#' @family SoftwareConfig functions
#' @export
SoftwareConfig.properties <- function() {
    list()
}

#' NodeInitializationAction Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Specifies an executable to run on a fully configured node and a timeout period for executable completion.
#' 
#' @param executableFile [Required] Google Cloud Storage URI of executable file
#' @param executionTimeout [Optional] Amount of time executable has to complete
#' 
#' @return NodeInitializationAction object
#' 
#' @family NodeInitializationAction functions
#' @export
NodeInitializationAction <- function(executableFile = NULL, executionTimeout = NULL) {
    structure(list(executableFile = executableFile, executionTimeout = executionTimeout), 
        class = "gar_NodeInitializationAction")
}

#' ClusterStatus Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' The status of a cluster and its instances.
#' 
#' @param state The cluster's state
#' @param detail Optional details of cluster's state
#' @param stateStartTime Time when this state was entered
#' 
#' @return ClusterStatus object
#' 
#' @family ClusterStatus functions
#' @export
ClusterStatus <- function(state = NULL, detail = NULL, stateStartTime = NULL) {
    structure(list(state = state, detail = detail, stateStartTime = stateStartTime), 
        class = "gar_ClusterStatus")
}

#' Operation Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' This resource represents a long-running operation that is the result of a network API call.
#' 
#' @param Operation.metadata The \link{Operation.metadata} object or list of objects
#' @param Operation.response The \link{Operation.response} object or list of objects
#' @param name The server-assigned name, which is only unique within the same service that originally returns it
#' @param metadata Service-specific metadata associated with the operation
#' @param done If the value is `false`, it means the operation is still in progress
#' @param error The error result of the operation in case of failure
#' @param response The normal response of the operation in case of success
#' 
#' @return Operation object
#' 
#' @family Operation functions
#' @export
Operation <- function(Operation.metadata = NULL, Operation.response = NULL, name = NULL, 
    metadata = NULL, done = NULL, error = NULL, response = NULL) {
    structure(list(Operation.metadata = Operation.metadata, Operation.response = Operation.response, 
        name = name, metadata = metadata, done = done, error = error, response = response), 
        class = "gar_Operation")
}

#' Operation.metadata Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Service-specific metadata associated with the operation. It typically contains progress information and common metadata such as create time. Some services might not provide such metadata. Any method that returns a long-running operation should document the metadata type, if any.
#' 
#' 
#' 
#' @return Operation.metadata object
#' 
#' @family Operation functions
#' @export
Operation.metadata <- function() {
    list()
}

#' Operation.response Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' The normal response of the operation in case of success. If the original method returns no data on success, such as `Delete`, the response is `google.protobuf.Empty`. If the original method is standard `Get`/`Create`/`Update`, the response should be the resource. For other methods, the response should have the type `XxxResponse`, where `Xxx` is the original method name. For example, if the original method name is `TakeSnapshot()`, the inferred response type is `TakeSnapshotResponse`.
#' 
#' 
#' 
#' @return Operation.response object
#' 
#' @family Operation functions
#' @export
Operation.response <- function() {
    list()
}

#' Status Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' The `Status` type defines a logical error model that is suitable for different programming environments, including REST APIs and RPC APIs. It is used by [gRPC](https://github.com/grpc). The error model is designed to be: - Simple to use and understand for most users - Flexible enough to meet unexpected needs # Overview The `Status` message contains three pieces of data: error code, error message, and error details. The error code should be an enum value of google.rpc.Code, but it may accept additional error codes if needed. The error message should be a developer-facing English message that helps developers *understand* and *resolve* the error. If a localized user-facing error message is needed, put the localized message in the error details or localize it in the client. The optional error details may contain arbitrary information about the error. There is a predefined set of error detail types in the package `google.rpc` which can be used for common error conditions. # Language mapping The `Status` message is the logical representation of the error model, but it is not necessarily the actual wire format. When the `Status` message is exposed in different client libraries and different wire protocols, it can be mapped differently. For example, it will likely be mapped to some exceptions in Java, but more likely mapped to some error codes in C. # Other uses The error model and the `Status` message can be used in a variety of environments, either with or without APIs, to provide a consistent developer experience across different environments. Example uses of this error model include: - Partial errors. If a service needs to return partial errors to the client, it may embed the `Status` in the normal response to indicate the partial errors. - Workflow errors. A typical workflow has multiple steps. Each step may have a `Status` message for error reporting purpose. - Batch operations. If a client uses batch request and batch response, the `Status` message should be used directly inside batch response, one for each error sub-response. - Asynchronous operations. If an API call embeds asynchronous operation results in its response, the status of those operations should be represented directly using the `Status` message. - Logging. If some API errors are stored in logs, the message `Status` could be used directly after any stripping needed for security/privacy reasons.
#' 
#' @param code The status code, which should be an enum value of google
#' @param message A developer-facing error message, which should be in English
#' @param details A list of messages that carry the error details
#' 
#' @return Status object
#' 
#' @family Status functions
#' @export
Status <- function(code = NULL, message = NULL, details = NULL) {
    structure(list(code = code, message = message, details = details), class = "gar_Status")
}

#' ListClustersResponse Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' The list of all clusters in a project.
#' 
#' @param clusters [Output-only] The clusters in the project
#' @param nextPageToken [Optional] This token is included in the response if there are more results to fetch
#' 
#' @return ListClustersResponse object
#' 
#' @family ListClustersResponse functions
#' @export
ListClustersResponse <- function(clusters = NULL, nextPageToken = NULL) {
    structure(list(clusters = clusters, nextPageToken = nextPageToken), class = "gar_ListClustersResponse")
}

#' DiagnoseClusterRequest Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' A request to collect cluster diagnostic information.
#' 
#' 
#' 
#' @return DiagnoseClusterRequest object
#' 
#' @family DiagnoseClusterRequest functions
#' @export
DiagnoseClusterRequest <- function() {
    list()
}

#' SubmitJobRequest Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' A request to submit a job.
#' 
#' @param job [Required] The job resource
#' 
#' @return SubmitJobRequest object
#' 
#' @family SubmitJobRequest functions
#' @export
SubmitJobRequest <- function(job = NULL) {
    structure(list(job = job), class = "gar_SubmitJobRequest")
}

#' Job Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' A Cloud Dataproc job resource.
#' 
#' @param reference [Optional] The fully qualified reference to the job, which can be used to obtain the equivalent REST path of the job resource
#' @param placement [Required] Job information, including how, when, and where to run the job
#' @param hadoopJob Job is a Hadoop job
#' @param sparkJob Job is a Spark job
#' @param pysparkJob Job is a Pyspark job
#' @param hiveJob Job is a Hive job
#' @param pigJob Job is a Pig job
#' @param sparkSqlJob Job is a SparkSql job
#' @param status [Output-only] The job status
#' @param statusHistory [Output-only] The previous job status
#' @param driverOutputResourceUri [Output-only] A URI pointing to the location of the stdout of the job's driver program
#' @param driverControlFilesUri [Output-only] If present, the location of miscellaneous control files which may be used as part of job setup and handling
#' 
#' @return Job object
#' 
#' @family Job functions
#' @export
Job <- function(reference = NULL, placement = NULL, hadoopJob = NULL, sparkJob = NULL, 
    pysparkJob = NULL, hiveJob = NULL, pigJob = NULL, sparkSqlJob = NULL, status = NULL, 
    statusHistory = NULL, driverOutputResourceUri = NULL, driverControlFilesUri = NULL) {
    structure(list(reference = reference, placement = placement, hadoopJob = hadoopJob, 
        sparkJob = sparkJob, pysparkJob = pysparkJob, hiveJob = hiveJob, pigJob = pigJob, 
        sparkSqlJob = sparkSqlJob, status = status, statusHistory = statusHistory, 
        driverOutputResourceUri = driverOutputResourceUri, driverControlFilesUri = driverControlFilesUri), 
        class = "gar_Job")
}

#' JobReference Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Encapsulates the full scoping used to reference a job.
#' 
#' @param projectId [Required] The ID of the Google Cloud Platform project that the job belongs to
#' @param jobId [Required] The job ID, which must be unique within the project
#' 
#' @return JobReference object
#' 
#' @family JobReference functions
#' @export
JobReference <- function(projectId = NULL, jobId = NULL) {
    structure(list(projectId = projectId, jobId = jobId), class = "gar_JobReference")
}

#' JobPlacement Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Cloud Dataproc job config.
#' 
#' @param clusterName [Required] The name of the cluster where the job will be submitted
#' @param clusterUuid [Output-only] A cluster UUID generated by the Cloud Dataproc service when the job is submitted
#' 
#' @return JobPlacement object
#' 
#' @family JobPlacement functions
#' @export
JobPlacement <- function(clusterName = NULL, clusterUuid = NULL) {
    structure(list(clusterName = clusterName, clusterUuid = clusterUuid), class = "gar_JobPlacement")
}

#' HadoopJob Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' A Cloud Dataproc job for running Hadoop MapReduce jobs on YARN.
#' 
#' @param HadoopJob.properties The \link{HadoopJob.properties} object or list of objects
#' @param mainJarFileUri The HCFS URI of the jar file containing the main class
#' @param mainClass The name of the driver's main class
#' @param args [Optional] The arguments to pass to the driver
#' @param jarFileUris [Optional] Jar file URIs to add to the CLASSPATHs of the Hadoop driver and tasks
#' @param fileUris [Optional] HCFS (Hadoop Compatible Filesystem) URIs of files to be copied to the working directory of Hadoop drivers and distributed tasks
#' @param archiveUris [Optional] HCFS URIs of archives to be extracted in the working directory of Hadoop drivers and tasks
#' @param properties [Optional] A mapping of property names to values, used to configure Hadoop
#' @param loggingConfig [Optional] The runtime log config for job execution
#' 
#' @return HadoopJob object
#' 
#' @family HadoopJob functions
#' @export
HadoopJob <- function(HadoopJob.properties = NULL, mainJarFileUri = NULL, mainClass = NULL, 
    args = NULL, jarFileUris = NULL, fileUris = NULL, archiveUris = NULL, properties = NULL, 
    loggingConfig = NULL) {
    structure(list(HadoopJob.properties = HadoopJob.properties, mainJarFileUri = mainJarFileUri, 
        mainClass = mainClass, args = args, jarFileUris = jarFileUris, fileUris = fileUris, 
        archiveUris = archiveUris, properties = properties, loggingConfig = loggingConfig), 
        class = "gar_HadoopJob")
}

#' HadoopJob.properties Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' [Optional] A mapping of property names to values, used to configure Hadoop. Properties that conflict with values set by the Cloud Dataproc API may be overwritten. Can include properties set in /etc/hadoop/conf/*-site and classes in user code.
#' 
#' 
#' 
#' @return HadoopJob.properties object
#' 
#' @family HadoopJob functions
#' @export
HadoopJob.properties <- function() {
    list()
}

#' LoggingConfig Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' The runtime logging config of the job.
#' 
#' @param LoggingConfig.driverLogLevels The \link{LoggingConfig.driverLogLevels} object or list of objects
#' @param driverLogLevels The per-package log levels for the driver
#' 
#' @return LoggingConfig object
#' 
#' @family LoggingConfig functions
#' @export
LoggingConfig <- function(LoggingConfig.driverLogLevels = NULL, driverLogLevels = NULL) {
    structure(list(LoggingConfig.driverLogLevels = LoggingConfig.driverLogLevels, 
        driverLogLevels = driverLogLevels), class = "gar_LoggingConfig")
}

#' LoggingConfig.driverLogLevels Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' The per-package log levels for the driver. This may include 'root' package name to configure rootLogger. Examples: 'com.google = FATAL', 'root = INFO', 'org.apache = DEBUG'
#' 
#' 
#' 
#' @return LoggingConfig.driverLogLevels object
#' 
#' @family LoggingConfig functions
#' @export
LoggingConfig.driverLogLevels <- function() {
    list()
}

#' SparkJob Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' A Cloud Dataproc job for running Spark applications on YARN.
#' 
#' @param SparkJob.properties The \link{SparkJob.properties} object or list of objects
#' @param mainJarFileUri The HCFS URI of the jar file that contains the main class
#' @param mainClass The name of the driver's main class
#' @param args [Optional] The arguments to pass to the driver
#' @param jarFileUris [Optional] HCFS URIs of jar files to add to the CLASSPATHs of the Spark driver and tasks
#' @param fileUris [Optional] HCFS URIs of files to be copied to the working directory of Spark drivers and distributed tasks
#' @param archiveUris [Optional] HCFS URIs of archives to be extracted in the working directory of Spark drivers and tasks
#' @param properties [Optional] A mapping of property names to values, used to configure Spark
#' @param loggingConfig [Optional] The runtime log config for job execution
#' 
#' @return SparkJob object
#' 
#' @family SparkJob functions
#' @export
SparkJob <- function(SparkJob.properties = NULL, mainJarFileUri = NULL, mainClass = NULL, 
    args = NULL, jarFileUris = NULL, fileUris = NULL, archiveUris = NULL, properties = NULL, 
    loggingConfig = NULL) {
    structure(list(SparkJob.properties = SparkJob.properties, mainJarFileUri = mainJarFileUri, 
        mainClass = mainClass, args = args, jarFileUris = jarFileUris, fileUris = fileUris, 
        archiveUris = archiveUris, properties = properties, loggingConfig = loggingConfig), 
        class = "gar_SparkJob")
}

#' SparkJob.properties Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' [Optional] A mapping of property names to values, used to configure Spark. Properties that conflict with values set by the Cloud Dataproc API may be overwritten. Can include properties set in /etc/spark/conf/spark-defaults.conf and classes in user code.
#' 
#' 
#' 
#' @return SparkJob.properties object
#' 
#' @family SparkJob functions
#' @export
SparkJob.properties <- function() {
    list()
}

#' PySparkJob Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' A Cloud Dataproc job for running PySpark applications on YARN.
#' 
#' @param PySparkJob.properties The \link{PySparkJob.properties} object or list of objects
#' @param mainPythonFileUri [Required] The HCFS URI of the main Python file to use as the driver
#' @param args [Optional] The arguments to pass to the driver
#' @param pythonFileUris [Optional] HCFS file URIs of Python files to pass to the PySpark framework
#' @param jarFileUris [Optional] HCFS URIs of jar files to add to the CLASSPATHs of the Python driver and tasks
#' @param fileUris [Optional] HCFS URIs of files to be copied to the working directory of Python drivers and distributed tasks
#' @param archiveUris [Optional] HCFS URIs of archives to be extracted in the working directory of 
#' @param properties [Optional] A mapping of property names to values, used to configure PySpark
#' @param loggingConfig [Optional] The runtime log config for job execution
#' 
#' @return PySparkJob object
#' 
#' @family PySparkJob functions
#' @export
PySparkJob <- function(PySparkJob.properties = NULL, mainPythonFileUri = NULL, args = NULL, 
    pythonFileUris = NULL, jarFileUris = NULL, fileUris = NULL, archiveUris = NULL, 
    properties = NULL, loggingConfig = NULL) {
    structure(list(PySparkJob.properties = PySparkJob.properties, mainPythonFileUri = mainPythonFileUri, 
        args = args, pythonFileUris = pythonFileUris, jarFileUris = jarFileUris, 
        fileUris = fileUris, archiveUris = archiveUris, properties = properties, 
        loggingConfig = loggingConfig), class = "gar_PySparkJob")
}

#' PySparkJob.properties Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' [Optional] A mapping of property names to values, used to configure PySpark. Properties that conflict with values set by the Cloud Dataproc API may be overwritten. Can include properties set in /etc/spark/conf/spark-defaults.conf and classes in user code.
#' 
#' 
#' 
#' @return PySparkJob.properties object
#' 
#' @family PySparkJob functions
#' @export
PySparkJob.properties <- function() {
    list()
}

#' HiveJob Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' A Cloud Dataproc job for running Hive queries on YARN.
#' 
#' @param HiveJob.scriptVariables The \link{HiveJob.scriptVariables} object or list of objects
#' @param HiveJob.properties The \link{HiveJob.properties} object or list of objects
#' @param queryFileUri The HCFS URI of the script that contains Hive queries
#' @param queryList A list of queries
#' @param continueOnFailure [Optional] Whether to continue executing queries if a query fails
#' @param scriptVariables [Optional] Mapping of query variable names to values (equivalent to the Hive command: `SET name='value';`)
#' @param properties [Optional] A mapping of property names and values, used to configure Hive
#' @param jarFileUris [Optional] HCFS URIs of jar files to add to the CLASSPATH of the Hive server and Hadoop MapReduce (MR) tasks
#' 
#' @return HiveJob object
#' 
#' @family HiveJob functions
#' @export
HiveJob <- function(HiveJob.scriptVariables = NULL, HiveJob.properties = NULL, queryFileUri = NULL, 
    queryList = NULL, continueOnFailure = NULL, scriptVariables = NULL, properties = NULL, 
    jarFileUris = NULL) {
    structure(list(HiveJob.scriptVariables = HiveJob.scriptVariables, HiveJob.properties = HiveJob.properties, 
        queryFileUri = queryFileUri, queryList = queryList, continueOnFailure = continueOnFailure, 
        scriptVariables = scriptVariables, properties = properties, jarFileUris = jarFileUris), 
        class = "gar_HiveJob")
}

#' HiveJob.scriptVariables Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' [Optional] Mapping of query variable names to values (equivalent to the Hive command: `SET name='value';`).
#' 
#' 
#' 
#' @return HiveJob.scriptVariables object
#' 
#' @family HiveJob functions
#' @export
HiveJob.scriptVariables <- function() {
    list()
}

#' HiveJob.properties Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' [Optional] A mapping of property names and values, used to configure Hive. Properties that conflict with values set by the Cloud Dataproc API may be overwritten. Can include properties set in /etc/hadoop/conf/*-site.xml, /etc/hive/conf/hive-site.xml, and classes in user code.
#' 
#' 
#' 
#' @return HiveJob.properties object
#' 
#' @family HiveJob functions
#' @export
HiveJob.properties <- function() {
    list()
}

#' QueryList Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' A list of queries to run on a cluster.
#' 
#' @param queries [Required] The queries to execute
#' 
#' @return QueryList object
#' 
#' @family QueryList functions
#' @export
QueryList <- function(queries = NULL) {
    structure(list(queries = queries), class = "gar_QueryList")
}

#' PigJob Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' A Cloud Dataproc job for running Pig queries on YARN.
#' 
#' @param PigJob.scriptVariables The \link{PigJob.scriptVariables} object or list of objects
#' @param PigJob.properties The \link{PigJob.properties} object or list of objects
#' @param queryFileUri The HCFS URI of the script that contains the Pig queries
#' @param queryList A list of queries
#' @param continueOnFailure [Optional] Whether to continue executing queries if a query fails
#' @param scriptVariables [Optional] Mapping of query variable names to values (equivalent to the Pig command: `name=[value]`)
#' @param properties [Optional] A mapping of property names to values, used to configure Pig
#' @param jarFileUris [Optional] HCFS URIs of jar files to add to the CLASSPATH of the Pig Client and Hadoop MapReduce (MR) tasks
#' @param loggingConfig [Optional] The runtime log config for job execution
#' 
#' @return PigJob object
#' 
#' @family PigJob functions
#' @export
PigJob <- function(PigJob.scriptVariables = NULL, PigJob.properties = NULL, queryFileUri = NULL, 
    queryList = NULL, continueOnFailure = NULL, scriptVariables = NULL, properties = NULL, 
    jarFileUris = NULL, loggingConfig = NULL) {
    structure(list(PigJob.scriptVariables = PigJob.scriptVariables, PigJob.properties = PigJob.properties, 
        queryFileUri = queryFileUri, queryList = queryList, continueOnFailure = continueOnFailure, 
        scriptVariables = scriptVariables, properties = properties, jarFileUris = jarFileUris, 
        loggingConfig = loggingConfig), class = "gar_PigJob")
}

#' PigJob.scriptVariables Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' [Optional] Mapping of query variable names to values (equivalent to the Pig command: `name=[value]`).
#' 
#' 
#' 
#' @return PigJob.scriptVariables object
#' 
#' @family PigJob functions
#' @export
PigJob.scriptVariables <- function() {
    list()
}

#' PigJob.properties Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' [Optional] A mapping of property names to values, used to configure Pig. Properties that conflict with values set by the Cloud Dataproc API may be overwritten. Can include properties set in /etc/hadoop/conf/*-site.xml, /etc/pig/conf/pig.properties, and classes in user code.
#' 
#' 
#' 
#' @return PigJob.properties object
#' 
#' @family PigJob functions
#' @export
PigJob.properties <- function() {
    list()
}

#' SparkSqlJob Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' A Cloud Dataproc job for running Spark SQL queries.
#' 
#' @param SparkSqlJob.scriptVariables The \link{SparkSqlJob.scriptVariables} object or list of objects
#' @param SparkSqlJob.properties The \link{SparkSqlJob.properties} object or list of objects
#' @param queryFileUri The HCFS URI of the script that contains SQL queries
#' @param queryList A list of queries
#' @param scriptVariables [Optional] Mapping of query variable names to values (equivalent to the Spark SQL command: SET `name='value';`)
#' @param properties [Optional] A mapping of property names to values, used to configure Spark SQL's SparkConf
#' @param jarFileUris [Optional] HCFS URIs of jar files to be added to the Spark CLASSPATH
#' @param loggingConfig [Optional] The runtime log config for job execution
#' 
#' @return SparkSqlJob object
#' 
#' @family SparkSqlJob functions
#' @export
SparkSqlJob <- function(SparkSqlJob.scriptVariables = NULL, SparkSqlJob.properties = NULL, 
    queryFileUri = NULL, queryList = NULL, scriptVariables = NULL, properties = NULL, 
    jarFileUris = NULL, loggingConfig = NULL) {
    structure(list(SparkSqlJob.scriptVariables = SparkSqlJob.scriptVariables, SparkSqlJob.properties = SparkSqlJob.properties, 
        queryFileUri = queryFileUri, queryList = queryList, scriptVariables = scriptVariables, 
        properties = properties, jarFileUris = jarFileUris, loggingConfig = loggingConfig), 
        class = "gar_SparkSqlJob")
}

#' SparkSqlJob.scriptVariables Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' [Optional] Mapping of query variable names to values (equivalent to the Spark SQL command: SET `name='value';`).
#' 
#' 
#' 
#' @return SparkSqlJob.scriptVariables object
#' 
#' @family SparkSqlJob functions
#' @export
SparkSqlJob.scriptVariables <- function() {
    list()
}

#' SparkSqlJob.properties Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' [Optional] A mapping of property names to values, used to configure Spark SQL's SparkConf. Properties that conflict with values set by the Cloud Dataproc API may be overwritten.
#' 
#' 
#' 
#' @return SparkSqlJob.properties object
#' 
#' @family SparkSqlJob functions
#' @export
SparkSqlJob.properties <- function() {
    list()
}

#' JobStatus Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Cloud Dataproc job status.
#' 
#' @param state [Required] A state message specifying the overall job state
#' @param details [Optional] Job state details, such as an error description if the state is ERROR
#' @param stateStartTime [Output-only] The time when this state was entered
#' 
#' @return JobStatus object
#' 
#' @family JobStatus functions
#' @export
JobStatus <- function(state = NULL, details = NULL, stateStartTime = NULL) {
    structure(list(state = state, details = details, stateStartTime = stateStartTime), 
        class = "gar_JobStatus")
}

#' ListJobsResponse Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' A list of jobs in a project.
#' 
#' @param jobs [Output-only] Jobs list
#' @param nextPageToken [Optional] This token is included in the response if there are more results to fetch
#' 
#' @return ListJobsResponse object
#' 
#' @family ListJobsResponse functions
#' @export
ListJobsResponse <- function(jobs = NULL, nextPageToken = NULL) {
    structure(list(jobs = jobs, nextPageToken = nextPageToken), class = "gar_ListJobsResponse")
}

#' CancelJobRequest Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' A request to cancel a job.
#' 
#' 
#' 
#' @return CancelJobRequest object
#' 
#' @family CancelJobRequest functions
#' @export
CancelJobRequest <- function() {
    list()
}

#' Empty Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' A generic empty message that you can re-use to avoid defining duplicated empty messages in your APIs. A typical example is to use it as the request or the response type of an API method. For instance: service Foo { rpc Bar(google.protobuf.Empty) returns (google.protobuf.Empty); } The JSON representation for `Empty` is empty JSON object `{}`.
#' 
#' 
#' 
#' @return Empty object
#' 
#' @family Empty functions
#' @export
Empty <- function() {
    list()
}

#' ListOperationsResponse Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' The response message for Operations.ListOperations.
#' 
#' @param operations A list of operations that matches the specified filter in the request
#' @param nextPageToken The standard List next-page token
#' 
#' @return ListOperationsResponse object
#' 
#' @family ListOperationsResponse functions
#' @export
ListOperationsResponse <- function(operations = NULL, nextPageToken = NULL) {
    structure(list(operations = operations, nextPageToken = nextPageToken), class = "gar_ListOperationsResponse")
}

#' DiagnoseClusterResults Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' The location of diagnostic output.
#' 
#' @param outputUri [Output-only] The Google Cloud Storage URI of the diagnostic output
#' 
#' @return DiagnoseClusterResults object
#' 
#' @family DiagnoseClusterResults functions
#' @export
DiagnoseClusterResults <- function(outputUri = NULL) {
    structure(list(outputUri = outputUri), class = "gar_DiagnoseClusterResults")
}

#' ClusterOperationMetadata Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Metadata describing the operation.
#' 
#' @param clusterName Name of the cluster for the operation
#' @param clusterUuid Cluster UUId for the operation
#' @param status [Output-only] Current operation status
#' @param statusHistory [Output-only] The previous operation status
#' @param operationType [Output-only] The operation type
#' @param description [Output-only] Short description of operation
#' 
#' @return ClusterOperationMetadata object
#' 
#' @family ClusterOperationMetadata functions
#' @export
ClusterOperationMetadata <- function(clusterName = NULL, clusterUuid = NULL, status = NULL, 
    statusHistory = NULL, operationType = NULL, description = NULL) {
    structure(list(clusterName = clusterName, clusterUuid = clusterUuid, status = status, 
        statusHistory = statusHistory, operationType = operationType, description = description), 
        class = "gar_ClusterOperationMetadata")
}

#' ClusterOperationStatus Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' The status of the operation.
#' 
#' @param state A message containing the operation state
#' @param innerState A message containing the detailed operation state
#' @param details A message containing any operation metadata details
#' @param stateStartTime The time this state was entered
#' 
#' @return ClusterOperationStatus object
#' 
#' @family ClusterOperationStatus functions
#' @export
ClusterOperationStatus <- function(state = NULL, innerState = NULL, details = NULL, 
    stateStartTime = NULL) {
    structure(list(state = state, innerState = innerState, details = details, stateStartTime = stateStartTime), 
        class = "gar_ClusterOperationStatus")
}

#' DiagnoseClusterOutputLocation Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' The location where output from diagnostic command can be found.
#' 
#' @param outputUri [Output-only] The Google Cloud Storage URI of the diagnostic output
#' 
#' @return DiagnoseClusterOutputLocation object
#' 
#' @family DiagnoseClusterOutputLocation functions
#' @export
DiagnoseClusterOutputLocation <- function(outputUri = NULL) {
    structure(list(outputUri = outputUri), class = "gar_DiagnoseClusterOutputLocation")
}

#' OperationMetadata Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Metadata describing the operation.
#' 
#' @param state A message containing the operation state
#' @param innerState A message containing the detailed operation state
#' @param details A message containing any operation metadata details
#' @param insertTime The time that the operation was requested
#' @param startTime The time that the operation was started by the server
#' @param endTime The time that the operation completed
#' @param clusterName Name of the cluster for the operation
#' @param clusterUuid Cluster UUId for the operation
#' @param status [Output-only] Current operation status
#' @param statusHistory [Output-only] Previous operation status
#' @param operationType [Output-only] The operation type
#' @param description [Output-only] Short description of operation
#' 
#' @return OperationMetadata object
#' 
#' @family OperationMetadata functions
#' @export
OperationMetadata <- function(state = NULL, innerState = NULL, details = NULL, insertTime = NULL, 
    startTime = NULL, endTime = NULL, clusterName = NULL, clusterUuid = NULL, status = NULL, 
    statusHistory = NULL, operationType = NULL, description = NULL) {
    structure(list(state = state, innerState = innerState, details = details, insertTime = insertTime, 
        startTime = startTime, endTime = endTime, clusterName = clusterName, clusterUuid = clusterUuid, 
        status = status, statusHistory = statusHistory, operationType = operationType, 
        description = description), class = "gar_OperationMetadata")
}


#' OperationStatus Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' The status of the operation.
#' 
#' @param state A message containing the operation state
#' @param innerState A message containing the detailed operation state
#' @param details A message containing any operation metadata details
#' @param stateStartTime The time this state was entered
#' 
#' @return OperationStatus object
#' 
#' @family OperationStatus functions
#' @export


OperationStatus <- function(state = NULL, innerState = NULL, details = NULL, stateStartTime = NULL) {
    
    
    
    structure(list(state = state, innerState = innerState, details = details, stateStartTime = stateStartTime), 
        class = "gar_OperationStatus")
}

