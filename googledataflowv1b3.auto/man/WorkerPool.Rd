% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/dataflow_objects.R
\name{WorkerPool}
\alias{WorkerPool}
\title{WorkerPool Object}
\usage{
WorkerPool(WorkerPool.metadata = NULL, WorkerPool.poolArgs = NULL,
  numWorkers = NULL, packages = NULL, defaultPackageSet = NULL,
  machineType = NULL, teardownPolicy = NULL, diskSizeGb = NULL,
  diskType = NULL, diskSourceImage = NULL, zone = NULL,
  taskrunnerSettings = NULL, onHostMaintenance = NULL, dataDisks = NULL,
  metadata = NULL, autoscalingSettings = NULL, poolArgs = NULL,
  network = NULL, subnetwork = NULL, workerHarnessContainerImage = NULL,
  numThreadsPerWorker = NULL, ipConfiguration = NULL)
}
\arguments{
\item{WorkerPool.metadata}{The \link{WorkerPool.metadata} object or list of objects}

\item{WorkerPool.poolArgs}{The \link{WorkerPool.poolArgs} object or list of objects}

\item{numWorkers}{Number of Google Compute Engine workers in this pool needed to execute the job}

\item{packages}{Packages to be installed on workers}

\item{defaultPackageSet}{The default package set to install}

\item{machineType}{Machine type (e}

\item{teardownPolicy}{Sets the policy for determining when to turndown worker pool}

\item{diskSizeGb}{Size of root disk for VMs, in GB}

\item{diskType}{Type of root disk for VMs}

\item{diskSourceImage}{Fully qualified source image for disks}

\item{zone}{Zone to run the worker pools in}

\item{taskrunnerSettings}{Settings passed through to Google Compute Engine workers when using the standard Dataflow task runner}

\item{onHostMaintenance}{The action to take on host maintenance, as defined by the Google Compute Engine API}

\item{dataDisks}{Data disks that are used by a VM in this workflow}

\item{metadata}{Metadata to set on the Google Compute Engine VMs}

\item{autoscalingSettings}{Settings for autoscaling of this WorkerPool}

\item{poolArgs}{Extra arguments for this worker pool}

\item{network}{Network to which VMs will be assigned}

\item{subnetwork}{Subnetwork to which VMs will be assigned, if desired}

\item{workerHarnessContainerImage}{Docker container image that executes Dataflow worker harness, residing in Google Container Registry}

\item{numThreadsPerWorker}{The number of threads per worker harness}

\item{ipConfiguration}{Configuration for VM IPs}
}
\value{
WorkerPool object
}
\description{
WorkerPool Object
}
\details{
Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
Describes one particular pool of Dataflow workers to be instantiated by the Dataflow service in order to perform the computations required by a job. Note that a workflow job may use multiple pools, in order to match the various computational requirements of the various stages of the job.
}
\seealso{
Other WorkerPool functions: \code{\link{WorkerPool.metadata}},
  \code{\link{WorkerPool.poolArgs}}
}

